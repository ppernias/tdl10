% ============================================================================
% X. CONCLUSIONS AND FUTURE WORK
% ============================================================================

\section{Conclusions and Future Work}

\subsection{Summary of Contributions}

This paper has presented \tdl{} (Tutor Description Language), an evolution of \adl{} that implements a four-layer architecture for LLM-based tutoring systems. The main contributions are:

\begin{enumerate}
    \item \textbf{Decoupled architecture}: Separation of Engine, Instructional Model, Learning Sequence, and Content Source, enabling independent evolution and reuse.

    \item \textbf{Instructional model as explicit component}: Formalization of ``how to teach'' as a sequence of reusable instructional events, aligned with Gagn\'{e} and Bloom theories.

    \item \textbf{Methodology-content separation}: The same instructional model can be applied to courses from different disciplines; the same content can be taught with different methodologies.

    \item \textbf{Documented evolution from ADL 1.0}: Analysis of ADL~1.0 limitations for tutoring and design principles that guided \tdl{}.

    \item \textbf{Formal specification and tools}: JSON Schema schemas and Python validator to ensure correctness before deployment.

    \item \textbf{Cross-platform portability}: The same \tdl{} files work on ChatGPT, Claude, Gemini, and OpenWebUI without modification.

    \item \textbf{Alignment with ADL~2.0}: Demonstration that \tdl{} can be expressed as an ADL~2.0 profile, validating both the chronological development path and ADL~2.0's extensibility mechanisms.
\end{enumerate}

\tdl{} does not claim to be conceptually novel, but pragmatically useful: an accessible implementation of established principles, adapted to the reality of current LLMs.

\subsection{Research Agenda}

Empirical validation of \tdl{} requires answering specific research questions:

\begin{itemize}
    \item \textbf{RQ1}: Do \tdl{} tutors produce greater learning gains than LLMs without formal pedagogical structure?
    \item \textbf{RQ2}: Does \tdl{} reduce teaching load while maintaining or improving the quality of individualized attention?
    \item \textbf{RQ3}: Can teachers without advanced technical training create functional \tdl{} tutors in reasonable time?
    \item \textbf{RQ4}: Which instructional models are most effective for which types of content and student population?
\end{itemize}

\subsection{Hypotheses}

Based on the reviewed literature, we propose the following hypotheses:

\begin{itemize}
    \item \textbf{H1}: \tdl{} tutors with the Bloom 8-Step model will produce greater learning gains than LLMs with generic prompts, for technical content.

    \item \textbf{H2}: Teachers with deployed \tdl{} tutors will report less time spent on repetitive individualized attention.

    \item \textbf{H3}: Teachers without prior experience will achieve functional \tdl{} tutors in less than 2 hours of work.

    \item \textbf{H4}: Interactive models will be preferred for conceptual content; expository models for normative content.
\end{itemize}

\subsection{Proposed Experimental Design}

We plan a quasi-experimental study during the 2025-2026 academic year with three conditions:

\begin{enumerate}
    \item \textbf{TDL group}: Students with access to a \tdl{} tutor using the Bloom 8-Step model.
    \item \textbf{Generic LLM group}: Students with access to ChatGPT/Claude with a basic prompt.
    \item \textbf{Control group}: Students with traditional materials (notes, videos).
\end{enumerate}

Metrics:

\begin{itemize}
    \item Normalized gain pre-post on knowledge tests.
    \item Self-reported study time.
    \item Engagement (number and depth of interactions with the tutor).
    \item Student satisfaction (Likert scale).
    \item Teaching load (hours dedicated to individualized attention).
\end{itemize}

\subsection{Future Work}

We identify several directions for future work:

\textbf{Visual editor (TDL Maker)}: Development of a web tool that allows designing learning sequences visually, automatically generating the \yamlformat{}. This would eliminate the syntactic barrier for teachers without technical experience.

\textbf{Learning analytics}: Integration of hooks to record which events are executed, student response times, interaction patterns, and dropout points. This data would inform iterative improvement of models and sequences.

\textbf{Community repository}: Creation of an open repository of validated instructional models, where designers can share methodologies and teachers can discover models appropriate for their needs.

\textbf{Assessment extensions}: Adding sections for evaluation rubrics, grading criteria, and automatic generation of student progress reports.

\textbf{Lightweight student model}: Exploring the feasibility of incorporating a simplified student model, leveraging LLMs' conversational memory or external storage, to enable some history-based adaptation.

\textbf{LMS integration}: Developing connectors to integrate \tdl{} tutors with learning management systems (Moodle, Canvas), enabling authentication, progress tracking, and grade synchronization.

\textbf{ADL~2.0 profile formalization}: Completing the formal definition of TDL as an ADL~2.0 profile, including schema definitions and validation rules that ensure compliance with both specifications.

\subsection{Final Conclusion}

The promise of scaling personalized education through AI will not be fulfilled solely with more powerful language models. It requires methods for educators to transfer their pedagogical expertise to these systems. \tdl{} offers a pragmatic path toward this goal: it allows ``how to teach'' to be formalized as reusable knowledge while ``what to teach'' remains under the teacher's control.

By separating responsibilities into well-defined layers and aligning with established instructional design theories, \tdl{} facilitates collaboration among instructional designers, teachers, and content experts. The result is a framework that amplifies educators' impact without compromising their pedagogical authorship.

The alignment with ADL~2.0 validates \tdl{}'s architectural decisions as instances of sound software engineering principles, while simultaneously demonstrating that ADL~2.0's extensibility mechanisms are sufficient for real-world domain specializations. This bidirectional validation strengthens confidence in both specifications.

Empirical validation will determine whether the lessons of the past (particularly from IMS Learning Design) have been learned. \tdl{} is a proposal in that direction, subject to experimental scrutiny and iterative improvement.
